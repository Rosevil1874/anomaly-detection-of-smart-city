# 岚皋路166弄数据分析
异常检测部分只使用数据量最大的15号数据进行测试。

## 代码使用

main.py：主函数。

**数据处理：**
- dateparser.py：根据不同情况进行日期时间解析的几个函数；

- preprocess.py：数据预处理
	- 读取所有原文件，并聚合为同一个文件；
	- 将数据按照地址分解为小的独立的csv文件；
	- 删除同一设备在15秒内同一状态的数据；
	- 数据缺失的状态（主要是超时报警和报警解除）补充。

- counters.py：以各种时间维度计算设备各种状态出现的次数，进行数据格式转换；
	- 计算单元设备每小时/每日开门次数；
	- 计算单元设备**每日**漏报次数(omission_requency)、误报次数（未发出警报却出现解除警报状态）；
	- 计算单元设备**总**漏报次数(omission_requency)、误报次数（未发出警报却出现解除警报状态）；
	- 计算单元设备**每日**开门次数open_frequency、漏报次数(omission_requency)、超时报警次数（正常解除报警的情况）timeout_frequency；
	- 计算单元设备**总**开门次数open_frequency、漏报次数(omission_requency)、超时报警次数（正常解除报警的情况）timeout_frequency；
	- 计算单元设备**总**开门次数(工作日工作时段，工作日夜间，周末日间，凌晨)；
	- 计算每个设备一天中**每个小时**正常开门的总次数并转化为CSV文件（0时到1时之间的算作1时，以此类推）；
	- 计算每个设备一周中**每天**正常开门的总次数并转化为CSV文件（0时到1时之间的算作1时，以此类推）；
	- 将逐小时数据**按天**分开成单独的csv文件，方便绘图；
	- 将逐天数据**按周**分开成单独的csv文件，方便绘图；
	- 提取出春节期间正常开门次数数据；
	- 计算每个设备“正常开门4-超时未关门报警6-开门状态0-报警解除7”事件的时长；

- plt_analysis.py：分不同的时间维度未各设备画出各种状态、规律图。
	- 画出每个设备一天中每个小时对应的开门次数；
	- 画出每个设备一周中每天对应的开门次数；
	- 画出每个设备工作日/周末的一天开门次数模型；
	- 画出每个设备一周开门次数模型；
	- 每个设备的漏报、误报次数比较；
	- 画出每个设备一次超时事件开门时长1小时及以内（1-3小时，3-6小时，6-10，10小时以上）占比；
	- 计算所有设备一次超时事件开门时长占比并画出饼图	；
	- 画出每个设备春节期间每天开门次数图：

- statistical.py：算出一天中每小时/一周中每天的开门次数（最佳情况、上界、下界），保存数据并画出相应图示。


**聚类：**
- clusters.py： 层次聚类，以“工作日工作时段，工作日通勤时段，周末日间，凌晨”的开门次数作为属性进行划分。
- cluster1.py：DBSCAN聚类，属性同上。


**异常检测：**
- oneclass_SVM.py：单类支持向量机异常检测，结果很差。
- auto_encoder.py：使用自编码器进行预测，并使用MAE和MSE进行异常判别标准，效果不佳。
- FFT.py：使用Airbnb的异常检测方案，使用原序列减去周期和趋势得到误差项，效果很差。（这个应该是我实现的问题，没搞懂FFT怎么弄的。。。）
- LSTM.py：使用LSTM模型对序列进行预测，并使用MAE和MAPE结合找出异常；
- LSTM_class.py：使用类实现LSTM；



**基于统计的异常检测：**
- daily_anomaly.py：建立每个设备一天中24个小时的正常开门次数模型；
- weekly_anomaly.py：建立每个设备一周中7天的正常开门次数模型；


**自编码器：**
- autoencoder.py：将分时段聚类结果中第二类的数据聚合，使用自编码器训练并在15号设备测试。
使用ASE和ACE作为评价指标判定异常。


## 文件目录
1. code: 源码；
2. dataset: 数据集
	- excel文件：原始文件；
	- units: 按地址划分后的数据；
	- redundancy_deleted: 删除重复状态后的数据；
	- complete_units: 补充缺失状态后的数据；
3. counts: 数据统计计算
	- 1day: 各设备每天的开门总次数；
	- 1hour: 各设备每小时的开门总次数；
	- peer_day: 各设备每周中每天的开门总次数；
	- peer_hour: 各设备每天中每小时的开门总次数；
	- weeks_split: 将各设备每天开门总次数按周分成单独的文件；
	- days_split: 将各设备每小时开门总次数按天分成单独的文件；
	- sprint_festival: 各设备春节期间开门次数，按每小时/每天分开；
	- total_open_condition.csv: 分时段计算的各设备总开门次数(工作日工作时段，工作日夜间，周末日间，凌晨)；

4. imgs:
	- spring_festival：春节期间开门次数图示，别的画图函数没有运行。。。

5. clusters：包含聚类结果图和对应设备分类文件。

6. statistic_model：均值标准差模型
	Daily_workday：工作日一日模型
	Daily_weekend：周末一日模型
	Weekly: 一周模型

7. anomaly_result:
	- daily: 异常日期
		- anomalies：FFT模型检测出的异常；
		- corr_anomalies：与均值标准差模型对比后的正确异常结果（即使用均值标准差也表现为异常的）；
		- corr_rate.csv：每个设备对应的正确率；
		- total.csv：所有异常汇总；
		- LSTM：使用LSTM检测异常的结果。
	- hourly: 异常日期时间
		- anomalies：FFT模型检测出的异常；
		- corr_anomalies：与均值标准差模型对比后的正确异常结果（即使用均值标准差也表现为异常的）；
		- corr_rate.csv：每个设备对应的正确率；
		- total.csv：所有异常汇总；
		- LSTM：使用LSTM检测异常的结果。
