# 岚皋路166弄数据分析

## 代码使用

main.py：主函数。

**数据处理：**
- dateparser.py：根据不同情况进行日期时间解析的几个函数；

- preprocess.py：数据预处理
	- 读取所有原文件，并聚合为同一个文件；
	- 将数据按照地址分解为小的独立的csv文件；
	- 删除同一设备在15秒内同一状态的数据；
	- 数据缺失的状态（主要是超时报警和报警解除）补充。

- counters.py：以各种时间维度计算设备各种状态出现的次数，进行数据格式转换；
	- 计算单元设备每小时/每日开门次数；
	- 计算单元设备**每日**漏报次数(omission_requency)、误报次数（未发出警报却出现解除警报状态）；
	- 计算单元设备**总**漏报次数(omission_requency)、误报次数（未发出警报却出现解除警报状态）；
	- 计算单元设备**每日**开门次数open_frequency、漏报次数(omission_requency)、超时报警次数（正常解除报警的情况）timeout_frequency；
	- 计算单元设备**总**开门次数open_frequency、漏报次数(omission_requency)、超时报警次数（正常解除报警的情况）timeout_frequency；
	- 计算单元设备**总**开门次数(工作日工作时段，工作日夜间，周末日间，凌晨)；
	- 计算每个设备一天中**每个小时**正常开门的总次数并转化为CSV文件（0时到1时之间的算作1时，以此类推）；
	- 计算每个设备一周中**每天**正常开门的总次数并转化为CSV文件（0时到1时之间的算作1时，以此类推）；
	- 将逐小时数据**按天**分开成单独的csv文件，方便绘图；
	- 将逐天数据**按周**分开成单独的csv文件，方便绘图；
	- 提取出春节期间正常开门次数数据；
	- 计算每个设备“正常开门4-超时未关门报警6-开门状态0-报警解除7”事件的时长；

- plt_analysis.py：分不同的时间维度未各设备画出各种状态、规律图。
	- 画出每个设备一天中每个小时对应的开门次数；
	- 画出每个设备一周中每天对应的开门次数；
	- 画出每个设备工作日/周末的一天开门次数模型；
	- 画出每个设备一周开门次数模型；
	- 每个设备的漏报、误报次数比较；
	- 画出每个设备一次超时事件开门时长1小时及以内（1-3小时，3-6小时，6-10，10小时以上）占比；
	- 计算所有设备一次超时事件开门时长占比并画出饼图	；
	- 画出每个设备春节期间每天开门次数图：

- statistical.py：算出一天中每小时/一周中每天的开门次数（最佳情况、上界、下界），保存数据并画出相应图示。


**聚类：**
- clusters.py： 层次聚类，以“工作日工作时段，工作日通勤时段，周末日间，凌晨”的开门次数作为属性对小区的每个单元进行划分。
- cluster1.py：DBSCAN聚类，属性同上。


**异常检测：**
- oneclass_SVM.py：单类支持向量机异常检测，结果很差。
- auto_encoder.py：使用自编码器进行预测，并使用MAE和MSE进行异常判别标准，效果不佳。
- FFT.py：使用Airbnb的异常检测方案，使用原序列减去周期和趋势得到误差项，效果很差。（这个应该是我实现的问题，没搞懂FFT怎么弄的。。。）
- LSTM.py：使用LSTM模型对序列进行预测，并使用MAE和MSE结合找出异常；
- LSTM_class.py：使用类实现LSTM；

**建立告警规则**：
alarm.py：方法1，计算每个设备中在每个小时开始的超时事件次数和时长，据此设置新的告警规则并计算告警降低率。问题：只考虑了超时，未考虑一般规律。
alram_v2.py：
	- 方法2，计算每个设备在开门次数表现正常的每个小时内（将一次连续的超时事件分配到其跨越的每个小时）的超时事件次数和时长，以及考虑所有数据采集天数的平均时长，据此设置新的告警规则；
	- 使用DBSCAN聚类合并表现相似的设备报警规则。



## 文件目录
1. code: 源码；
2. dataset: 数据集
	- excel文件：原始文件；
	- units: 按地址划分后的数据；
	- redundancy_deleted: 删除重复状态后的数据；
	- complete_units: 补充缺失状态后的数据；
3. counts: 数据统计计算
	- 1day: 各设备每天的开门总次数；
	- 1hour: 各设备每小时的开门总次数；
	- peer_day: 各设备每周中每天的开门总次数；
	- peer_hour: 各设备每天中每小时的开门总次数；
	- weeks_split: 将各设备每天开门总次数按周分成单独的文件；
	- days_split: 将各设备每小时开门总次数按天分成单独的文件；
	- sprint_festival: 各设备春节期间开门次数，按每小时/每天分开；
	- open_to_close_time：每个设备“正常开门4-超时未关门报警6-开门状态0-报警解除7”事件（超时事件）的开始时间、结束事件、时长；
	- hourly_open_to_close_time：每个设备4个月数据中在每个小时内超时事件的次数、时长、最大、最小、平均时长；
	- hourly_start_open_to_close_time：每个设备4个月数据中开始时间在每个小时内超时事件的次数、时长；
	- unit_alarm_rules：为每个设备每个小时设置的告警规则（从这个小时开始的超时事件持续的时长上限）；
	- alarm_reduce_rate.csv：使用新规则后报警率降低的百分比；
	- total_open_condition.csv: 分时段计算的各设备总开门次数(工作日工作时段，工作日夜间，周末日间，凌晨)；

4. imgs:
	- spring_festival：春节期间开门次数图示，别的画图函数没有运行。。。

5. clusters：包含聚类结果图和对应设备分类文件。

6. statistic_model：均值标准差模型
	- daily_workday：工作日一日模型
	- daily_weekend：周末一日模型
	- weekly: 一周模型

7. anomaly_result:
	- daily: 异常日期
		- anomalies：FFT模型检测出的异常；
		- corr_anomalies：与均值标准差模型对比后的正确异常结果（即使用均值标准差也表现为异常的）；
		- corr_rate.csv：每个设备对应的正确率；
		- total.csv：所有异常汇总；
		- LSTM：使用LSTM检测异常的结果。
	- hourly: 异常日期时间
		- anomalies：FFT模型检测出的异常；
		- corr_anomalies：与均值标准差模型对比后的正确异常结果（即使用均值标准差也表现为异常的）；
		- corr_rate.csv：每个设备对应的正确率；
		- total.csv：所有异常汇总；
		- LSTM：使用LSTM检测异常的结果。

8. alarm_rules
	- auto_clusters：手肘法自动调参的DBSCAN聚类结果；
	- auto_merged: 自动调参聚类结果进行合并后的规则；
	- clusters: 手动调试参数的DBSCAN聚类结果；
	- merged: 手动调参聚类结果进行合并后的规则；
	- open_to_close_time：每个设备“正常开门4-超时未关门报警6-开门状态0-报警解除7”事件（超时事件）的开始时间、结束事件、时长；
	- hourly_open_to_close_time：每个设备4个月数据中在每个小时内超时事件的次数、时长、最大、最小、平均时长；
	- hourly_start_open_to_close_time：每个设备4个月数据中开始时间在每个小时内超时事件的次数、时长；
	- unit_alarm_rules：为每个设备每个小时设置的告警规则（从这个小时开始的超时事件持续的时长上限）；
	- total_open_condition.csv: 分时段计算的各设备总开门次数(工作日工作时段，工作日夜间，周末日间，凌晨)；
	- total_unit_alarm_rules.csv：所有设备告警规则。